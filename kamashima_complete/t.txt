### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [    678,     51 ]
[ FP(0,1), TN(0,0) ] = [   1655,    615 ]

### Marginal/Total Counts ###
True [ P, N ] = [    729,   2270 ]
Est  [ P, N ] = [   2333,    666 ]
Total       = 2999

### Accuracy ###
Acc / S.D. = [ 0.431143714571524, 0.00904324042502423 ]

### Mutual Information (natual log) ###
I(C;E) = 0.0257170340012722
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.0463699652664132, 0.0485666466466234 ]
Arithmetic Mean = 0.0474683059565183
Geometric Mean = 0.0474555973317173

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    102,      3 ]
    [ FP(0,1), TN(0,0) ] = [    673,    204 ]
S=1 [ TP(1,1), FN(1,0) ] = [    576,     48 ]
    [ FP(0,1), TN(0,0) ] = [    982,    411 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0272215525880977
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0490827382327792, 0.0430480579971106 ]
Arithmetic Mean = 0.0460653981149449
Geometric Mean = 0.0459664721520118

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 0.000180442199479547
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.000340765289723113, 0.000285350596487214 ]
Arithmetic Mean = 0.000313057943105164
Geometric Mean = 0.000311829406382126

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.677496526085967
D(E|S || C|S) = 0.722341458977647

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.578628076661849
Normalized = 0.409151836792523

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.202445708423411
Pr[E=1 | S=1] - Pr[E=1 | S=0] = -0.0167713942688775

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 34.5620202099326
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 102.171238911446
