### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [    846,    371 ]
[ FP(0,1), TN(0,0) ] = [    472,   3193 ]

### Marginal/Total Counts ###
True [ P, N ] = [   1217,   3665 ]
Est  [ P, N ] = [   1318,   3564 ]
Total       = 4882

### Accuracy ###
Acc / S.D. = [ 0.827324866857845, 0.00540946171272188 ]

### Mutual Information (natual log) ###
I(C;E) = 0.141612724395749
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.252183587547951, 0.24280755070103 ]
Arithmetic Mean = 0.247495569124491
Geometric Mean = 0.247451165322608

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    129,     42 ]
    [ FP(0,1), TN(0,0) ] = [    140,   1312 ]
S=1 [ TP(1,1), FN(1,0) ] = [    717,    329 ]
    [ FP(0,1), TN(0,0) ] = [    332,   1881 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0306606777476643
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.054600458709131, 0.0482164102664544 ]
Arithmetic Mean = 0.0514084344877927
Geometric Mean = 0.0513092400826212

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 0.014529792697213
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0249126156710669, 0.0228492811392182 ]
Arithmetic Mean = 0.0238809484051426
Geometric Mean = 0.0238586537629746

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.00491583053676157
D(E|S || C|S) = 0.00558385502224675

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.0511391559168971
Normalized = 0.0361608439329941

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.215596905257104
Pr[E=1 | S=1] - Pr[E=1 | S=0] = 0.156135424400357

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 32.8269298056499
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 51.4923405032637
