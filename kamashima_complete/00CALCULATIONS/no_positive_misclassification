### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [   1199,     18 ]
[ FP(0,1), TN(0,0) ] = [   2793,    873 ]

### Marginal/Total Counts ###
True [ P, N ] = [   1217,   3666 ]
Est  [ P, N ] = [   3992,    891 ]
Total       = 4883

### Accuracy ###
Acc / S.D. = [ 0.424329305754659, 0.00707286244548326 ]

### Mutual Information (natual log) ###
I(C;E) = 0.0438147112604261
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.0780329506951585, 0.0922185958916142 ]
Arithmetic Mean = 0.0851257732933863
Geometric Mean = 0.0848297656862677

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    170,      1 ]
    [ FP(0,1), TN(0,0) ] = [   1174,    279 ]
S=1 [ TP(1,1), FN(1,0) ] = [   1029,     17 ]
    [ FP(0,1), TN(0,0) ] = [   1619,    594 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0306903181017368
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0546587210176281, 0.0482557928871762 ]
Arithmetic Mean = 0.0514572569524021
Geometric Mean = 0.0513575692659281

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 0.000170162803743601
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.000358148539218801, 0.000267554770443637 ]
Arithmetic Mean = 0.000312851654831219
Geometric Mean = 0.000309555084266775

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.80207577774765
D(E|S || C|S) = 0.815711243736737

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.620051795604402
Normalized = 0.438442829358767

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.215661782377561
Pr[E=1 | S=1] - Pr[E=1 | S=0] = -0.0150670292346923

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 32.8067161789223
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 101.854359829149

### Balanced error rate ###
Balanced error rate: 0.612758
