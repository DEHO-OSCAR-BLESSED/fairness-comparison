### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [   1191,     16 ]
[ FP(0,1), TN(0,0) ] = [   3005,    672 ]

### Marginal/Total Counts ###
True [ P, N ] = [   1207,   3677 ]
Est  [ P, N ] = [   4196,    688 ]
Total       = 4884

### Accuracy ###
Acc / S.D. = [ 0.381449631449631, 0.0069505361614282 ]

### Mutual Information (natual log) ###
I(C;E) = 0.0310936967037246
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.055607472255989, 0.0764844310832476 ]
Arithmetic Mean = 0.0660459516696183
Geometric Mean = 0.0652158407097294

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    186,      0 ]
    [ FP(0,1), TN(0,0) ] = [   1245,    183 ]
S=1 [ TP(1,1), FN(1,0) ] = [   1005,     16 ]
    [ FP(0,1), TN(0,0) ] = [   1760,    489 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0253798033158354
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0453888362710736, 0.0399991387061204 ]
Arithmetic Mean = 0.042693987488597
Geometric Mean = 0.0426088530438929

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 0.00158993164025945
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.00391092182204027, 0.00250576789034086 ]
Arithmetic Mean = 0.00320834485619057
Geometric Mean = 0.00313047317881848

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 1.00255737588635
D(E|S || C|S) = 0.930415479973362

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.674496610310142
Normalized = 0.476941127037641

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.196990780214408
Pr[E=1 | S=1] - Pr[E=1 | S=0] = -0.0410513511362732

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 36.9089273946018
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 104.854897584651

### Balanced error rate ###
Balanced error rate: 0.657247
