### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [   2793,   1053 ]
[ FP(0,1), TN(0,0) ] = [   1772,  10663 ]

### Marginal/Total Counts ###
True [ P, N ] = [   3846,  12435 ]
Est  [ P, N ] = [   4565,  11716 ]
Total       = 16281

### Accuracy ###
Acc / S.D. = [ 0.826484859652356, 0.00296787496814352 ]

### Mutual Information (natual log) ###
I(C;E) = 0.141908085764424
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.259576476433708, 0.239176480224592 ]
Arithmetic Mean = 0.24937647832915
Geometric Mean = 0.249167790820796

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    331,    259 ]
    [ FP(0,1), TN(0,0) ] = [    224,   4607 ]
S=1 [ TP(1,1), FN(1,0) ] = [   2462,    794 ]
    [ FP(0,1), TN(0,0) ] = [   1548,   6056 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0247622087821844
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0452947192527536, 0.0389184772324297 ]
Arithmetic Mean = 0.0421065982425916
Geometric Mean = 0.0419857297184125

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 0.0440700818512412
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.074277142162903, 0.0692644380897406 ]
Arithmetic Mean = 0.0717707901263218
Geometric Mean = 0.0717270138429397

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.00719014681698476
D(E|S || C|S) = 0.00743930504578655

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.0604558386159109
Normalized = 0.0427487334476302

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.190979829820801
Pr[E=1 | S=1] - Pr[E=1 | S=0] = 0.266865300789543

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 36.3009535671406
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 27.7267539507623
