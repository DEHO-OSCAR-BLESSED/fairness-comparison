### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [    341,     10 ]
[ FP(0,1), TN(0,0) ] = [    145,      4 ]

### Marginal/Total Counts ###
True [ P, N ] = [    351,    149 ]
Est  [ P, N ] = [    486,     14 ]
Total       = 500

### Accuracy ###
Acc / S.D. = [ 0.69, 0.0206833266183175 ]

### Mutual Information (natual log) ###
I(C;E) = 1.04742750650644e-05
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 1.71946157585697e-05, 8.20098558209906e-05 ]
Arithmetic Mean = 4.96022357897802e-05
Geometric Mean = 3.75516705255257e-05

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    102,      3 ]
    [ FP(0,1), TN(0,0) ] = [     52,      1 ]
S=1 [ TP(1,1), FN(1,0) ] = [    239,      7 ]
    [ FP(0,1), TN(0,0) ] = [     93,      3 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.00153018060021548
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.00251195116592645, 0.00245292981000096 ]
Arithmetic Mean = 0.0024824404879637
Geometric Mean = 0.00248226507371143

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 6.22138271273442e-05
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.000487112183047694, 9.97308102935162e-05 ]
Arithmetic Mean = 0.000293421496670605
Geometric Mean = 0.000220408921596178

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.480230593462812
D(E|S || C|S) = 0.251123850807407

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.407487246513698
Normalized = 0.28813699525687

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.0547412835887187
Pr[E=1 | S=1] - Pr[E=1 | S=0] = -0.00392331038566884

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 92.3896264279098
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 100.404148238524

### Balanced error rate ###
Balanced error rate: 0.320249
