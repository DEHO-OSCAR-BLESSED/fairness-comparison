### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [   2273,      0 ]
[ FP(0,1), TN(0,0) ] = [   6769,      7 ]

### Marginal/Total Counts ###
True [ P, N ] = [   2273,   6776 ]
Est  [ P, N ] = [   9042,      7 ]
Total       = 9049

### Accuracy ###
Acc / S.D. = [ 0.251961542711902, 0.00456382305799051 ]

### Mutual Information (natual log) ###
I(C;E) = 0.000223867813839762
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.000397184727297435, 0.0354474685412253 ]
Arithmetic Mean = 0.0179223266342614
Geometric Mean = 0.0037522250899874

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [    351,      0 ]
    [ FP(0,1), TN(0,0) ] = [   2526,      1 ]
S=1 [ TP(1,1), FN(1,0) ] = [   1922,      0 ]
    [ FP(0,1), TN(0,0) ] = [   4243,      6 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0227117647509616
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0402950559722308, 0.0363162812486639 ]
Arithmetic Mean = 0.0383056686104474
Geometric Mean = 0.0382539747688811

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 6.31990203431299e-05
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0100070003232035, 0.000101055704943578 ]
Arithmetic Mean = 0.00505402801407353
Geometric Mean = 0.00100561646368382

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 4.94030245919932
D(E|S || C|S) = 1.45768873961811

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.98523796385972
Normalized = 0.696668445327635

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.189497119898505
Pr[E=1 | S=1] - Pr[E=1 | S=0] = -0.000624826226012454

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 39.1578185799336
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 100.06254343294

### Balanced error rate ###
Balanced error rate: 0.782632
