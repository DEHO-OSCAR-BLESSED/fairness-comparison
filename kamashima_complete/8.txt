### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [      7,   1119 ]
[ FP(0,1), TN(0,0) ] = [     12,   3746 ]

### Marginal/Total Counts ###
True [ P, N ] = [   1126,   3758 ]
Est  [ P, N ] = [     19,   4865 ]
Total       = 4884

### Accuracy ###
Acc / S.D. = [ 0.768427518427518, 0.00603610939055133 ]

### Mutual Information (natual log) ###
I(C;E) = 0.000187524790004834
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.000347307665379547, 0.00736234727497481 ]
Arithmetic Mean = 0.00385482747017718
Geometric Mean = 0.00159906211379826

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [      1,    162 ]
    [ FP(0,1), TN(0,0) ] = [      7,   1415 ]
S=1 [ TP(1,1), FN(1,0) ] = [      6,    957 ]
    [ FP(0,1), TN(0,0) ] = [      5,   2331 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.0245464498026375
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.0454615636369492, 0.0389480083315228 ]
Arithmetic Mean = 0.042204785984236
Geometric Mean = 0.0420789419935429

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 7.95362265512134e-05
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.00312264485562688, 0.000126200637537477 ]
Arithmetic Mean = 0.00162442274658218
Geometric Mean = 0.000627757733192699

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.788772245209861
D(E|S || C|S) = 0.248529107637483

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.441523587142594
Normalized = 0.312204322522338

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.189067521656022
Pr[E=1 | S=1] - Pr[E=1 | S=0] = -0.00171297487145995

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 35.2301397774436
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 151.373673644967

### Balanced error rate ###
Balanced error rate: 0.199114
