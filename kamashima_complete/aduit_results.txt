### Contingency Table ###
[ TP(1,1), FN(1,0) ] = [    198,    191 ]
[ FP(0,1), TN(0,0) ] = [   1025,   3384 ]

### Marginal/Total Counts ###
True [ P, N ] = [    389,   4409 ]
Est  [ P, N ] = [   1223,   3575 ]
Total       = 4798

### Accuracy ###
Acc / S.D. = [ 0.746561067111296, 0.00627970457047815 ]

### Mutual Information (natual log) ###
I(C;E) = 0.0131772838944908
[ I(C;E)/H(C), I(C;E)/H(E) ] = [ 0.0468295599594554, 0.0232136531112326 ]
Arithmetic Mean = 0.035021606535344
Geometric Mean = 0.0329709745116893

### Contingency Table with Sensitive Attribute ###
S=0 [ TP(1,1), FN(1,0) ] = [     27,     40 ]
    [ FP(0,1), TN(0,0) ] = [    167,    805 ]
S=1 [ TP(1,1), FN(1,0) ] = [    171,    151 ]
    [ FP(0,1), TN(0,0) ] = [    858,   2579 ]

### Mutual Information (Correct, Sensitive) ###
I(C;S) = 0.00053653206415738
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.00190673287984127, 0.00102684628832232 ]
Arithmetic Mean = 0.00146678958408179
Geometric Mean = 0.00139925751042727

### Mutual Information (Estimated, Sensitive) ###
I(C;S) = 0.00355566672993968
[ I(C;S)/H(C), I(C;ES)/H(S) ] = [ 0.00626381086640161, 0.00680504191279559 ]
Arithmetic Mean = 0.0065344263895986
Geometric Mean = 0.00652882037428565

### KL-Divergence Given Sensitive ###
D(C|S || E|S) = 0.100521448639996
D(E|S || C|S) = 0.136454600621271

### Hellinger distance jointed with S ###
d_H(P(C,S), P(E,S)) = 0.240642751729405
Normalized = 0.170160121591253

### Caldars-Verwer score ###
Pr[C=1 | S=1] - Pr[C=1 | S=0] = 0.0211759982650558
Pr[E=1 | S=1] - Pr[E=1 | S=0] = 0.0870250186847043

### P-Score score ###
P-Rule between Sensitive feature and correct class: Pr[C=0 | S=1] / Pr[C=1 | S=1] = 75.2793237644893
P-Rule between Sensitive feature and estimated class: Pr[E=0 | S=1] / Pr[E=1 | S=1] = 68.2092278682407
